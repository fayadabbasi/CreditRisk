{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "import scipy.stats as stat\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression_with_p_values:\n",
    "    \"\"\"\n",
    "    Wrapper Class for Logistic Regression which has the usual sklearn instance \n",
    "    in an attribute self.model, and pvalues, z scores and estimated \n",
    "    errors for each coefficient in \n",
    "\n",
    "    self.z_scores\n",
    "    self.p_values\n",
    "    self.sigma_estimates\n",
    "\n",
    "    as well as the negative hessian of the log Likelihood (Fisher information)\n",
    "\n",
    "    self.F_ij\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.model = linear_model.LogisticRegression(*args, **kwargs)\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X,y)\n",
    "        # Get p-values for the fitted model\n",
    "        denom = (2.0 * (1+np.cosh(self.model.decision_function(X)))) #desc_func predicts confidence score\n",
    "        denom = np.tile(denom,(X.shape[1], 1)).T\n",
    "        F_ij = np.dot((X / denom).T,X) # Fisher Information Matrix\n",
    "        Cramer_Rao = np.linalg.inv(F_ij) # Inverse Information Matrix\n",
    "        sigma_estimates = np.sqrt(np.diagonal(Cramer_Rao))\n",
    "        z_scores = self.model.coef_[0] / sigma_estimates # z-score for eaach model coefficient\n",
    "        p_values = [stat.norm.sf(abs(x)) * 2 for x in z_scores] # two tailed test for p-values\n",
    "        self.coef_ = self.model.coef_\n",
    "        self.intercept_ = self.model.intercept_\n",
    "        self.p_values = p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression_with_p_values(linear_model.LinearRegression):\n",
    "    \"\"\"\n",
    "    LinearRegression class after sklearn's, but calculate t-statistics\n",
    "    and p-values for model coefficients (betas).\n",
    "    Additional attributes available after .fit()\n",
    "    are `t` and `p` which are of the shape (y.shape[1], X.shape[1])\n",
    "    which is (n_features, n_coefs)\n",
    "    This class sets the intercept to 0 by default, since usually we include it\n",
    "    in X.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fit_intercept=True, normalize=False, copy_X = True, n_jobs=1):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.normalize = normalize\n",
    "        self.copy_X = copy_X\n",
    "        self.n_jobs = n_jobs\n",
    "    def fit(self, X, y, n_jobs=1):\n",
    "        self = super(LinearRegression, self).fit(X, y, n_jobs)\n",
    "        sse = np.sum((self.predict(X) - y) ** 2, axis=0) / float(X.shape[0] - X.shape[1])\n",
    "        se = np.array([np.sqrt(np.diagonal(sse * np.linalg.inv(np.dot(X.T, X))))])\n",
    "        self.t = self.coef_ / se\n",
    "        self.p = np.squeeze(2 * (1 - stat.t.cdf(np.abs(self.t), y.shape[0] - X.shape[1])))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def woe_discrete(df, discrete_variable_name, good_bad_variable_df):\n",
    "    df = pd.concat([df[discrete_variable_name], good_bad_variable_df],axis=1)\n",
    "    df = pd.concat([df.groupby(df.columns.values[0], as_index=False)[df.columns.values[1]].count(),df.groupby(df.columns.values[0], as_index=False)[df.columns.values[1]].mean()], axis=1)\n",
    "    df = df.iloc[:,[0,1,3]]\n",
    "    df.columns = [df.columns.values[0], 'n_obs', 'prop_good']\n",
    "    df['prop_n_obs'] = df['n_obs'] / df['n_obs'].sum()\n",
    "    df['n_good'] = df['prop_good'] * df['n_obs']\n",
    "    df['n_bad'] = (1-df['prop_good']) * df['n_obs']\n",
    "    df['prop_n_good'] = df['n_good']/ df['n_good'].sum()\n",
    "    df['prop_n_bad'] = df['n_bad'] / df['n_bad'].sum()\n",
    "    df['WoE'] = np.log(df['prop_n_good'] / df['prop_n_bad'])\n",
    "    df = df.sort_values(['WoE'])\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['diff_prop_good'] = df['prop_good'].diff().abs()\n",
    "    df['diff_WoE'] = df['WoE'].diff().abs()\n",
    "    df['IV'] = (df['prop_n_good'] - df['prop_n_bad']) * df['WoE']\n",
    "    df['IV'] = df['IV'].sum()\n",
    "    return df\n",
    "    # for df use df_inputs_prepr, for discrete_variable_name use 'grade', for good_bad_variable_df use df_targets_prepr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def woe_ordered_continuous(df, discrete_variable_name, good_bad_variable_df):\n",
    "    df = pd.concat([df[discrete_variable_name], good_bad_variable_df],axis=1)\n",
    "    df = pd.concat([df.groupby(df.columns.values[0], as_index=False)[df.columns.values[1]].count(),df.groupby(df.columns.values[0], as_index=False)[df.columns.values[1]].mean()], axis=1)\n",
    "    df = df.iloc[:,[0,1,3]]\n",
    "    df.columns = [df.columns.values[0], 'n_obs', 'prop_good']\n",
    "    df['prop_n_obs'] = df['n_obs'] / df['n_obs'].sum()\n",
    "    df['n_good'] = df['prop_good'] * df['n_obs']\n",
    "    df['n_bad'] = (1-df['prop_good']) * df['n_obs']\n",
    "    df['prop_n_good'] = df['n_good']/ df['n_good'].sum()\n",
    "    df['prop_n_bad'] = df['n_bad'] / df['n_bad'].sum()\n",
    "    df['WoE'] = np.log(df['prop_n_good'] / df['prop_n_bad'])\n",
    "    df['diff_prop_good'] = df['prop_good'].diff().abs()\n",
    "    df['diff_WoE'] = df['WoE'].diff().abs()\n",
    "    df['IV'] = (df['prop_n_good'] - df['prop_n_bad']) * df['WoE']\n",
    "    df['IV'] = df['IV'].sum()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_woe(df_WoE, rotation_of_x_axis_label=0):\n",
    "    x = np.array(df_WoE.iloc[:,0].apply(str))\n",
    "    y = df_WoE['WoE']\n",
    "    plt.figure(figsize=(18,6))\n",
    "    plt.plot(x,y,marker='o', linestyle='--',color='k')\n",
    "    plt.xlabel = (df_WoE.columns[0])\n",
    "    plt.ylabel = ('Weight of Evidence')\n",
    "    plt.title(str('Weight of Evidence by '+ df_WoE.columns[0]))\n",
    "    plt.xticks(rotation=rotation_of_x_axis_label)\n",
    "    # plot_by_woe(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to work on this to make it look cleaner but going in the right direction\n",
    "def pre_processing(dframe, date='2019-8-01'):\n",
    "    def emp_length(dataframe,column='emp_length'):\n",
    "        dataframe[column+'_int'] = dataframe[column]\n",
    "        dataframe[column+'_int'] = dataframe[column+'_int'].str.replace('\\+ years','')\n",
    "        dataframe[column+'_int'] = dataframe[column+'_int'].str.replace('< 1 year',str(0))\n",
    "        dataframe[column+'_int'] = dataframe[column+'_int'].str.replace('n\\a',str(0))\n",
    "        dataframe[column+'_int'] = dataframe[column+'_int'].str.replace(' years','')\n",
    "        dataframe[column+'_int'] = dataframe[column+'_int'].str.replace(' year','')\n",
    "        dataframe[column+'_int'] = pd.to_numeric(dataframe[column+'_int'])\n",
    "        dataframe[column+'_int'].fillna(0, inplace=True)\n",
    "    \n",
    "    def term_length(dataframe, column='term'):\n",
    "        dataframe[column+'_int'] = dataframe[column]\n",
    "        dataframe[column+'_int'] = dataframe[column].str.replace(' months','')\n",
    "        dataframe[column+'_int'] = pd.to_numeric(dataframe[column+'_int'])\n",
    "        \n",
    "    emp_length(dframe)\n",
    "    term_length(dframe)\n",
    "    dframe = dframe[dframe['earliest_cr_line'].notnull()]\n",
    "    dframe['earliest_cr_line_date'] = pd.to_datetime(dframe['earliest_cr_line'], format = '%b-%Y')\n",
    "    dframe['mths_since_earliest_cr_line'] = round(pd.to_numeric((pd.to_datetime(date)-dframe['earliest_cr_line_date'])/np.timedelta64(1,'M')))\n",
    "    dframe['issue_d_date'] = pd.to_datetime(dframe['issue_d'], format = '%b-%Y')\n",
    "    dframe['mths_since_issue_d'] = round(pd.to_numeric((pd.to_datetime(date) - dframe['issue_d_date']) / np.timedelta64(1, 'M')))\n",
    "    dframe['total_rev_hi_lim'].fillna(dframe['funded_amnt'], inplace=True)\n",
    "    dframe['annual_inc'].fillna(dframe['annual_inc'].mean(), inplace=True)\n",
    "    dframe['good_bad'] = np.where(dframe['loan_status'].isin(['Charged Off','Default','Does not meet the credit policy. Status:Fully Paid','Does not meet the credit policy. Status:Charged Off','Late (31-120 days)','Late (16-30 days)']),0,1)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_na = ['mths_since_earliest_cr_line','acc_now_delinq','total_acc','pub_rec','open_acc','inq_last_6mths','delinq_2yrs','emp_length_int']\n",
    "def fill_na(dataframe, lst_na):\n",
    "    for items in lst:\n",
    "        dataframe[items].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_ohe = ['grade','sub_grade','home_ownership','verification_status','loan_status','purpose','addr_state','initial_list_status']\n",
    "def loan_data_d(dataframe, lst_ohe):\n",
    "    for items in lst:\n",
    "        loan_data_dummies = [pd.get_dummies(dataframe[items], prefix=items,prefix_sep=':')]\n",
    "        loan_data_dummies = pd.concat(loan_data_dummies, axis=1)\n",
    "        dataframe = pd.concat([dataframe, loan_data_dummies], axis = 1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
